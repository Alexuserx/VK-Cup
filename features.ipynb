{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from recommenders.als_recommender import get_als_similarity_features\n",
    "from recommenders.bm25_recommender import get_bm25_similarity_features\n",
    "from recommenders.content_recommender import get_content_similarity_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val candidates shape: 149_810_474\n",
      "Test candidates shape: 146_573_625\n"
     ]
    }
   ],
   "source": [
    "merged_candidates_val = pd.read_parquet('./data/candidates/merged_candidates_val.parquet.gzip')\n",
    "print(f'Val candidates shape: {merged_candidates_val.shape[0]:_}')\n",
    "\n",
    "merged_candidates_test = pd.read_parquet('./data/candidates/merged_candidates_test.parquet.gzip')\n",
    "print(f'Test candidates shape: {merged_candidates_test.shape[0]:_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet('./data/train.parquet.gzip').rename_axis('timestamp')\n",
    "\n",
    "train_split = pd.read_parquet('./data/splits/train.parquet.gzip')\n",
    "val_no_targets = pd.read_parquet('./data/splits/val_no_targets.parquet.gzip')\n",
    "val_targets = pd.read_parquet('./data/splits/val_targets.parquet.gzip')\n",
    "\n",
    "test_df = pd.read_parquet('./data/test.parquet.gzip')\n",
    "items_meta_df = pd.read_parquet('./data/items_meta.parquet.gzip')\n",
    "fresh_candidates_df = pd.read_parquet('./data/fresh_candidates.parquet.gzip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users candidates df w shape: 149_810_474\n",
      "Users history df w shape: 20_379_394\n",
      "Users candidates list len: 200_000\n",
      "Users history list len: 200_000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [04:18<00:00, 772.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users candidates df w shape: 146_573_625\n",
      "Users history df w shape: 32_219_777\n",
      "Users candidates list len: 200_000\n",
      "Users history list len: 200_000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [07:04<00:00, 470.69it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('./models/als/recommender_val.pkl', 'rb') as f1:\n",
    "    als_recommender_val = pickle.load(f1)\n",
    "\n",
    "als_features_val = get_als_similarity_features(\n",
    "    als_model = als_recommender_val,\n",
    "    candidates_df = merged_candidates_val, \n",
    "    history_df = val_no_targets\n",
    "    )\n",
    "\n",
    "\n",
    "with open('./models/als/recommender_test.pkl', 'rb') as f2:\n",
    "    als_reccomender_test = pickle.load(f2)\n",
    "\n",
    "als_features_test = get_als_similarity_features(\n",
    "    als_model = als_reccomender_test,\n",
    "    candidates_df = merged_candidates_test, \n",
    "    history_df = train_df[train_df.user_id.isin(test_df.user_id.values)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val features shape: 149_810_474\n",
      "Test features shape: 146_573_625\n"
     ]
    }
   ],
   "source": [
    "print(f'Val features shape: {als_features_val.shape[0]:_}')\n",
    "print(f'Test features shape: {als_features_test.shape[0]:_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>als_sim_mean</th>\n",
       "      <th>als_sim_min</th>\n",
       "      <th>als_sim_max</th>\n",
       "      <th>als_sim_std</th>\n",
       "      <th>als_sim_score</th>\n",
       "      <th>als_sim_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>93615</td>\n",
       "      <td>0.294215</td>\n",
       "      <td>0.032840</td>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>0.514802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>87797</td>\n",
       "      <td>0.378960</td>\n",
       "      <td>-0.143124</td>\n",
       "      <td>0.745198</td>\n",
       "      <td>0.158539</td>\n",
       "      <td>0.234164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>159229</td>\n",
       "      <td>0.340893</td>\n",
       "      <td>0.048582</td>\n",
       "      <td>0.912253</td>\n",
       "      <td>0.205390</td>\n",
       "      <td>0.224879</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  als_sim_mean  als_sim_min  als_sim_max  als_sim_std  \\\n",
       "0        4    93615      0.294215     0.032840     0.734460     0.146107   \n",
       "1        4    87797      0.378960    -0.143124     0.745198     0.158539   \n",
       "2        4   159229      0.340893     0.048582     0.912253     0.205390   \n",
       "\n",
       "   als_sim_score  als_sim_rank  \n",
       "0       0.514802             0  \n",
       "1       0.234164             1  \n",
       "2       0.224879             2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_features_val.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_features_val.to_parquet('./data/features/als_features_val.parquet.gzip', compression='gzip')\n",
    "als_features_test.to_parquet('./data/features/als_features_test.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users candidates df w shape: 149_810_474\n",
      "Users history df w shape: 20_379_394\n",
      "Users candidates list len: 200_000\n",
      "Users history list len: 200_000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [15:03<00:00, 221.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users candidates df w shape: 146_573_625\n",
      "Users history df w shape: 32_219_777\n",
      "Users candidates list len: 200_000\n",
      "Users history list len: 200_000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [13:52<00:00, 240.17it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('./models/bm25/recommender_val.pkl', 'rb') as f1:\n",
    "    i2i_model_val = pickle.load(f1)\n",
    "\n",
    "bm25_features_val = get_bm25_similarity_features(\n",
    "    i2i_model = i2i_model_val, \n",
    "    candidates_df = merged_candidates_val, \n",
    "    history_df = val_no_targets\n",
    "    )\n",
    "\n",
    "\n",
    "with open('./models/bm25/recommender_test.pkl', 'rb') as f2:\n",
    "    i2i_model_test = pickle.load(f2)\n",
    "\n",
    "bm25_features_test = get_bm25_similarity_features(\n",
    "    i2i_model = i2i_model_test, \n",
    "    candidates_df = merged_candidates_test, \n",
    "    history_df = train_df[train_df.user_id.isin(test_df.user_id.values)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val features shape: 149_810_474\n",
      "Test features shape: 146_573_625\n"
     ]
    }
   ],
   "source": [
    "print(f'Val features shape: {bm25_features_val.shape[0]:_}')\n",
    "print(f'Test features shape: {bm25_features_test.shape[0]:_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_features_val.to_parquet('./data/features/bm25_features_val.parquet.gzip', compression='gzip')\n",
    "bm25_features_test.to_parquet('./data/features/bm25_features_test.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users candidates df w shape: 149_810_474\n",
      "Users history df w shape: 20_379_394\n",
      "Users candidates list len: 200_000\n",
      "Users history list len: 200_000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [09:28<00:00, 351.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users candidates df w shape: 146_573_625\n",
      "Users history df w shape: 32_219_777\n",
      "Users candidates list len: 200_000\n",
      "Users history list len: 200_000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [09:07<00:00, 365.43it/s]\n"
     ]
    }
   ],
   "source": [
    "content_features_val = get_content_similarity_features(\n",
    "    embeddings_matrix = np.stack(items_meta_df['embeddings'].to_numpy(), axis=0), \n",
    "    candidates_df = merged_candidates_val, \n",
    "    history_df = val_no_targets\n",
    "    )\n",
    "\n",
    "content_features_test = get_content_similarity_features(\n",
    "    embeddings_matrix = np.stack(items_meta_df['embeddings'].to_numpy(), axis=0), \n",
    "    candidates_df = merged_candidates_test, \n",
    "    history_df = train_df[train_df.user_id.isin(test_df.user_id.values)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val features shape: 149_810_474\n",
      "Test features shape: 146_573_625\n"
     ]
    }
   ],
   "source": [
    "print(f'Val features shape: {content_features_val.shape[0]:_}')\n",
    "print(f'Test features shape: {content_features_test.shape[0]:_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_sim_mean</th>\n",
       "      <th>content_sim_min</th>\n",
       "      <th>content_sim_max</th>\n",
       "      <th>content_sim_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>93615</td>\n",
       "      <td>0.688007</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.865685</td>\n",
       "      <td>0.070550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>87797</td>\n",
       "      <td>0.766864</td>\n",
       "      <td>0.538591</td>\n",
       "      <td>0.935280</td>\n",
       "      <td>0.076561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>159229</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.542229</td>\n",
       "      <td>0.887457</td>\n",
       "      <td>0.076913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  content_sim_mean  content_sim_min  content_sim_max  \\\n",
       "0        4    93615          0.688007         0.457500         0.865685   \n",
       "1        4    87797          0.766864         0.538591         0.935280   \n",
       "2        4   159229          0.759494         0.542229         0.887457   \n",
       "\n",
       "   content_sim_std  \n",
       "0         0.070550  \n",
       "1         0.076561  \n",
       "2         0.076913  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_features_val.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_features_val.to_parquet('./data/features/content_features_val.parquet.gzip', compression='gzip')\n",
    "content_features_test.to_parquet('./data/features/content_features_test.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User - Item - Source features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rank(df_pd: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_pl = pl.from_pandas(df_pd.reset_index())\n",
    "    df_pl = df_pl.sort(['user_id', 'timestamp'])\n",
    "    df_pl = df_pl.with_columns([\n",
    "        pl.col('item_id')\n",
    "        .cumcount(reverse=True)\n",
    "        .over(['user_id'])\n",
    "        .alias('rank')\n",
    "        ])\n",
    "    return df_pl.to_pandas().set_index('timestamp')\n",
    "\n",
    "train_split = calculate_rank(train_split)\n",
    "train_df = calculate_rank(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_source_item_stats(train_df, items_meta_df):\n",
    "    train_df = pd.merge(train_df, items_meta_df.drop(columns='embeddings'), on=['item_id'])\n",
    "    \n",
    "    si_stats_df = train_df.groupby(['source_id', 'item_id'], as_index=False).agg(\n",
    "        source_item_cnt = ('user_id', 'count'),\n",
    "        source_item_total_timespent = ('timespent', 'sum'), \n",
    "        source_item_cnt_nz = ('timespent', lambda x: np.nonzero(list(x))[0].shape[0])\n",
    "        )\n",
    "\n",
    "    si_stats_df['source_item_retention_perc'] = si_stats_df['source_item_cnt_nz'] / si_stats_df['source_item_cnt']\n",
    "    si_stats_df['source_item_timespent_perc'] = si_stats_df['source_item_total_timespent'] / si_stats_df['source_item_cnt']\n",
    "    si_stats_df['source_item_timespent_perc_nz'] = si_stats_df['source_item_total_timespent'] / si_stats_df['source_item_cnt_nz']\n",
    "\n",
    "    si_stats_df = si_stats_df.sort_values(['source_id', 'source_item_timespent_perc'], ascending=[True, False])\n",
    "    si_stats_df['source_item_rank'] = si_stats_df.groupby('source_id', sort=False).cumcount()\n",
    "\n",
    "    si_stats_df['source_item_count_norm'] = si_stats_df['source_item_cnt']\\\n",
    "                                            / si_stats_df.groupby('source_id')['source_item_cnt'].transform('sum')\n",
    "    si_stats_df['source_item_timespent_norm'] = si_stats_df['source_item_total_timespent']\\\n",
    "                                                / si_stats_df.groupby('source_id')['source_item_total_timespent'].transform('sum')\n",
    "\n",
    "    del si_stats_df['source_item_cnt']\n",
    "    del si_stats_df['source_item_cnt_nz']\n",
    "    del si_stats_df['source_item_total_timespent']\n",
    "\n",
    "    return si_stats_df\n",
    "\n",
    "si_stats_val = calc_source_item_stats(train_split, items_meta_df)\n",
    "si_stats_test = calc_source_item_stats(train_df, items_meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_stats_val.to_parquet('./data/features/source_item_features_val.parquet.gzip', compression='gzip')\n",
    "si_stats_test.to_parquet('./data/features/source_item_features_test.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(train_df, shifts, column):\n",
    "    stats_dfs = None\n",
    "    for shift in shifts:\n",
    "        train_part = train_df[train_df['rank'] <= shift]\n",
    "\n",
    "        stats = train_part[['user_id', column, 'timespent']].groupby(column, as_index=False).agg(\n",
    "              **{f'{column}_mean_timespent_shift_{shift}': ('timespent', 'mean')})\n",
    "\n",
    "        if stats_dfs is not None:\n",
    "            stats_dfs = stats_dfs.merge(stats, how='right')\n",
    "        else:\n",
    "            stats_dfs = stats\n",
    "    return stats_dfs.fillna(0)\n",
    "\n",
    "def get_sources_popularity_stats(train_df, items_meta_df, shifts):\n",
    "    train_df = pd.merge(train_df, items_meta_df.drop(columns='embeddings'), on=['item_id'])\n",
    "    sources_stats = get_stats(train_df, shifts, 'source_id')\n",
    "    return sources_stats\n",
    "\n",
    "sources_stats_val= get_sources_popularity_stats(train_split, items_meta_df, [0, 10, 50, 100])\n",
    "sources_stats_test = get_sources_popularity_stats(train_df, items_meta_df, [0, 10, 50, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_stats_val.to_parquet('./data/features/sources_features_val.parquet.gzip', compression='gzip')\n",
    "sources_stats_test.to_parquet('./data/features/sources_features_test.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_popularity_stats(train_df, offsets):\n",
    "    item_stats = get_stats(train_df, offsets, 'item_id')\n",
    "    return item_stats\n",
    "\n",
    "item_stats_val = get_items_popularity_stats(train_split, [0, 10, 50, 100])\n",
    "item_stats_test = get_items_popularity_stats(train_df, [0, 10, 50, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_stats_val.to_parquet('./data/features/items_features_val.parquet.gzip', compression='gzip')\n",
    "item_stats_test.to_parquet('./data/features/items_features_test.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_source_stats(val_test_df, items_meta_df):\n",
    "    val_test_df = pd.merge(val_test_df, items_meta_df.drop(columns='embeddings'), on=['item_id'])\n",
    "    user_source_stats = val_test_df[['user_id', 'source_id', 'timespent']].\\\n",
    "        groupby(['user_id', 'source_id'], as_index=False).\\\n",
    "            agg(**{'timespent_per_view': ('timespent', 'mean')})\n",
    "    return user_source_stats\n",
    "\n",
    "user_source_stats_val= get_user_source_stats(val_no_targets, items_meta_df)\n",
    "user_source_stats_test = get_user_source_stats(train_df[train_df.user_id.isin(test_df.user_id.values)], items_meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_source_stats_val.to_parquet('./data/features/user_source_features_val.parquet.gzip', compression='gzip')\n",
    "user_source_stats_test.to_parquet('./data/features/user_source_features_test.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_stats(val_test_df, items_meta_df):\n",
    "    val_test_df = pd.merge(val_test_df, items_meta_df.drop(columns='embeddings'), on=['item_id'])\n",
    "    user_stats = val_test_df[['user_id', 'source_id', 'timespent']].groupby('user_id', as_index=False).agg(\n",
    "        **{'total_views': ('source_id', 'count'),\n",
    "           'total_timespent': ('timespent', 'sum'), \n",
    "           'unique_sources': ('source_id', 'nunique')})\n",
    "\n",
    "    user_stats['views_per_artist'] = user_stats['total_views'] / user_stats['unique_sources']\n",
    "    user_stats['timespent_per_artist'] = user_stats['total_timespent'] / user_stats['unique_sources']\n",
    "\n",
    "    del user_stats['total_views']\n",
    "    del user_stats['unique_sources']\n",
    "\n",
    "    return user_stats\n",
    "\n",
    "user_stats_val = get_user_stats(val_no_targets, items_meta_df)\n",
    "user_stats_test = get_user_stats(train_df[train_df.user_id.isin(test_df.user_id.values)], items_meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stats_val.to_parquet('./data/features/user_features_val.parquet.gzip', compression='gzip')\n",
    "user_stats_test.to_parquet('./data/features/user_features_test.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be9aa36d7e3afdff118a475fbad3be8b1fefaba27a5e9b3c7f20b4e187884c51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
